{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "list_dict = {'Current_uA':time_points_r, 'E_field_V/cm':fv} \n",
    "df = pd.DataFrame(list_dict) \n",
    "df.to_csv('current_efield.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ROOT import TCanvas, TGraph, TFile, TH1F, TH2D\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def collect_pulse_data(file):\n",
    "    myFile = TFile.Open(file, \"read\")\n",
    "    data = myFile.Get(\"PulseTransfer\")\n",
    "    detector = data.Get(\"detector1\")\n",
    "    pulsed_array = []\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    for key in detector.GetListOfKeys():\n",
    "        name = key.GetName()\n",
    "        graph = detector.Get(name)\n",
    "        if type(graph) != TGraph:\n",
    "            continue\n",
    "        else:\n",
    "            searching = re.search(\"ke\", graph.GetTitle())\n",
    "            if searching != None and name[:10] == \"current_ev\":\n",
    "                a = graph.GetTitle()[43:searching.start()]\n",
    "                pulsed_array.append(a)\n",
    "                event = detector.Get(name)\n",
    "                x = event.GetX()\n",
    "                y = event.GetY()\n",
    "                data_x.append(x)\n",
    "                data_y.append(y)\n",
    "                \n",
    "    return pulsed_array, data_x, data_y\n",
    "\n",
    "def collect_efield(file, position):\n",
    "    field_values = []\n",
    "    for f, p in zip(file, position):\n",
    "        myFile = TFile.Open(f, \"read\")\n",
    "        data = myFile.Get(\"ElectricFieldReader\")\n",
    "        detector = data.Get(\"detector1\")\n",
    "        efield = detector.Get(\"field1d_z\")\n",
    "        no_bins = efield.GetNbinsX()\n",
    "        bin_size = 0.1/no_bins\n",
    "        \n",
    "        pos = p*10**(-3)\n",
    "            \n",
    "        placement = -0.05\n",
    "        for bin in range(no_bins):  \n",
    "            placement += bin_size\n",
    "            if placement >= pos:\n",
    "                field_strength = efield.GetBinContent(bin) \n",
    "                field_values.append(field_strength)\n",
    "                break\n",
    "                \n",
    "    return field_values\n",
    "\n",
    "def fit_convolve_data(x_data, y_data, time):\n",
    "    time_points_r = []\n",
    "    time_points_c = []\n",
    "    \n",
    "    for x_pos, y_pos in zip(x_data, y_data):\n",
    "        if x_pos == [] and y_pos == []:\n",
    "            time_points_r.append(0)\n",
    "            time_points_c.append(0)\n",
    "            \n",
    "        else:\n",
    "            for x, y in zip(x_pos, y_pos):  \n",
    "\n",
    "                dx = x[1]-x[0]\n",
    "                x_pdf = np.arange(x[0], x[-1], dx)        \n",
    "                y_pdf = sc.stats.norm.pdf(x_pdf, 0.1, 0.075) \n",
    "                y_convolve = sc.signal.fftconvolve(np.abs(y), y_pdf, mode='full')*dx\n",
    "                x_convolve = np.linspace(0, x[-1], len(y_convolve))\n",
    "                \n",
    "                for i in range(len(x)):\n",
    "                    if x[i] >= 0.6 and x[i-1] < 0.6:\n",
    "                        hole_index = i\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                for i in range(len(x_convolve)):\n",
    "                    if x_convolve[i] >= 0.35 and x_convolve[i-1] < 0.35:\n",
    "                        hole_index_c = i\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                hole_cont = np.abs(y[hole_index])\n",
    "                hole_cont_c = np.abs(y_convolve[hole_index_c])\n",
    "                \n",
    "                for i in range(len(x_convolve)):\n",
    "                    if x_convolve[i] >= time and x_convolve[i-1] < time:\n",
    "                        time_index_c = i\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                for i in range(len(x)):\n",
    "                    if x[i] >= time and x[i-1] < time:\n",
    "                        time_index_r = i\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                time_point_raw = np.abs(y[time_index_r])-hole_cont\n",
    "                time_points_r.append(time_point_raw)\n",
    "                \n",
    "                time_point_con = np.abs(y_convolve[time_index_c])-hole_cont_c\n",
    "                time_points_c.append(time_point_con)\n",
    "        \n",
    "    return time_points_r, time_points_c\n",
    "\n",
    "def fit_data_less_overbias(x_data, y_data, time, p):\n",
    "    time_points_r = []\n",
    "    time_points_c = []\n",
    "    \n",
    "    for x_pos, y_pos, position in zip(x_data, y_data, p):\n",
    "\n",
    "        if x_pos == [] and y_pos == []:\n",
    "            time_points_r.append(0)\n",
    "            time_points_c.append(0)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            for x, y in zip(x_pos, y_pos):  \n",
    "                dx = x[1]-x[0]\n",
    "                x_pdf = np.arange(x[0], x[-1], dx)        \n",
    "                y_pdf = sc.stats.norm.pdf(x_pdf, 0.07, 0.075) \n",
    "                y_convolve = sc.signal.fftconvolve(np.abs(y), y_pdf, mode='full')*dx\n",
    "                x_convolve = np.linspace(0, x[-1], len(y_convolve))\n",
    "                \n",
    "                for i in range(len(x)):\n",
    "                    if x[i] >= 4.5 and x[i-1] < 4.5:\n",
    "                        hole_index = i\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                for i in range(len(x_convolve)):\n",
    "                    if x_convolve[i] >= 3 and x_convolve[i-1] < 3:\n",
    "                        hole_index_c = i\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                hole_cont = np.abs(y[hole_index])\n",
    "                hole_cont_c = np.abs(y_convolve[hole_index_c])\n",
    "                \n",
    "                for i in range(len(x)):\n",
    "                    if x[i] >= time and x[i-1] < time:\n",
    "                        time_index_r = i\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                \n",
    "                t_point_r = np.abs(y[time_index_r]) - hole_cont\n",
    "                time_points_r.append(t_point_r)\n",
    "                \n",
    "                for i in range(len(x_convolve)):\n",
    "                    if x_convolve[i] >= time and x_convolve[i-1] < time:\n",
    "                        time_index_c = i\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                t_point_c = np.abs(y_convolve[time_index_c]) - hole_cont_c\n",
    "                time_points_c.append(t_point_c)\n",
    "        \n",
    "    return time_points_r, time_points_c\n",
    "\n",
    "files1 = [\"data_10ps_n40.root\", \"extra_data_n35.root\", \"data_10ps_n30.root\", \"extra_data_n25.root\",\"data_10ps_n20.root\", \"extra_data_n15.root\", \"data_10ps_n10.root\", \"extra_data_n5.root\", \"data_10ps_0.root\"] \n",
    "files2 = [\"less_overbias_n45.root\", \"less_overbias_n40.root\", \"less_overbias_n35.root\", \"less_overbias_n30.root\", \"less_overbias_n25.root\", \"less_overbias_n20.root\", \"less_overbias_n15.root\", \"less_overboas_n10.root\", \"less_overbias_n5.root\", \"less_overbias_0.root\", \"less_overbias_p5.root\", \"less_overbias_p10.root\", \"less_overbias_p15.root\", \"less_overbias_p20.root\", \"less_overbias_p25.root\", \"less_overbias_p30.root\"]\n",
    "position1 = [40, 35, 30, 25, 20, 15, 10, 5, 0] \n",
    "position2 = [45, 40, 35, 30, 25, 20, 15, 10, 5, 0, -5, -10, -15, -20, -25, -30]\n",
    "\n",
    "x_values1, y_values1, pulse_names1 = [], [], []\n",
    "for dat in files1:\n",
    "    pulse, x_dat, y_dat = collect_pulse_data(dat)\n",
    "    pulse_names1.append(pulse)\n",
    "    x_values1.append(x_dat)\n",
    "    y_values1.append(y_dat)\n",
    "    \n",
    "x_values2, y_values2, pulse_names2 = [], [], []\n",
    "for dat in files2:\n",
    "    pulse, x_dat, y_dat = collect_pulse_data(dat)\n",
    "    pulse_names2.append(pulse)\n",
    "    x_values2.append(x_dat)\n",
    "    y_values2.append(y_dat)\n",
    "\n",
    "fv = collect_efield(files1, position1) + collect_efield(files2, position2)\n",
    "time_points_r1, time_points_c1 = fit_convolve_data(x_values1, y_values1, 0.1) \n",
    "time_points_r2, time_points_c2 = fit_data_less_overbias(x_values2, y_values2, 0.07, position2) \n",
    "time_points_r = time_points_r1+time_points_r2\n",
    "\n",
    "for f, t in zip(fv, time_points_r):\n",
    "    print(f,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "list_dict = {'Current_uA':time_points_r, 'E_field_V/cm':np.abs(fv)} \n",
    "df = pd.DataFrame(list_dict) \n",
    "df.to_csv('current_efield.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "column_names = ['Current_uA', 'E_field_V/cm']\n",
    "\n",
    "raw_dataset = pd.read_csv('current_efield.csv', names=column_names)\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()\n",
    "dataset.isna().sum()\n",
    "dataset = dataset.dropna()\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "train_dataset.describe().transpose()\n",
    "\n",
    "train_dataset.describe().transpose()\n",
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "test_features['Current_uA'].pop(0)\n",
    "\n",
    "train_labels = train_features.pop('E_field_V/cm')\n",
    "test_labels = test_features.pop('E_field_V/cm')\n",
    "\n",
    "current = np.array(train_features, dtype=\"float32\")\n",
    "normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
    "normalizer.adapt(current)\n",
    "\n",
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(1),\n",
    "      layers.Dense(10000, activation='relu'),\n",
    "      layers.Dense(10000, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model\n",
    "\n",
    "model = build_and_compile_model(normalizer)\n",
    "\n",
    "train_features['Current_uA'] = train_features['Current_uA'].astype(float)\n",
    "train_labels = train_labels.astype(float)\n",
    "\n",
    "history = model.fit(\n",
    "    train_features['Current_uA'],\n",
    "    train_labels,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  #plt.ylim(0,1000)\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  \n",
    "plot_loss(history)\n",
    "print(history.history['loss'])\n",
    "\n",
    "x = np.array([0.5])\n",
    "test_features['Current_uA'] = test_features['Current_uA'].astype(float)\n",
    "test_labels = test_labels.astype(float)\n",
    "test_features['Current_uA'].pop(0)\n",
    "\n",
    "y = model.predict(test_features['Current_uA'])\n",
    "y1 = model.predict([x])\n",
    "print(y1)\n",
    "print(y)\n",
    "test_results = {}\n",
    "test_results['E_field_model'] = model.evaluate(\n",
    "    test_features['Current_uA'], test_labels,\n",
    "    verbose=0)\n",
    "\n",
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(train_features['Current_uA'], train_labels, label='Data')\n",
    "plt.plot(test_features['Current_uA'], y, color='k', label='Predictions')\n",
    "plt.xlabel('Current')\n",
    "plt.ylabel('E_field')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
