{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import array as arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ROOT import TCanvas, TGraph, TFile, TH1F, TH2D\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def collect_pulse_data(file):\n",
    "    myFile = TFile.Open(file, \"read\")\n",
    "    data = myFile.Get(\"PulseTransfer\")\n",
    "    detector = data.Get(\"detector1\")\n",
    "    pulsed_array = []\n",
    "    for key in detector.GetListOfKeys():\n",
    "        name = key.GetName()\n",
    "        graph = detector.Get(name)\n",
    "        if type(graph) != TGraph:\n",
    "            continue\n",
    "        else:\n",
    "            searching = re.search(\"ke\", graph.GetTitle())\n",
    "            if searching != None and name[:10] == \"current_ev\":\n",
    "                a = graph.GetTitle()[43:searching.start()]\n",
    "                pulsed_array.append(a)\n",
    "                event = detector.Get(name)\n",
    "                x = event.GetX()\n",
    "                y = event.GetY()\n",
    "                x_title = event.GetXaxis()\n",
    "                if (str(x_title))[22:-1] != 'ns':\n",
    "                    print('Units have changed')\n",
    "                    break\n",
    "                \n",
    "    return pulsed_array, x, y\n",
    "\n",
    "def collect_efield(files_tot, position):\n",
    "    each_field = arr.array('f', [])\n",
    "    for file in files_tot:\n",
    "        field_values = arr.array('f', [])\n",
    "        for f, p in zip(file, position):\n",
    "            myFile = TFile.Open(f, \"read\")\n",
    "            data = myFile.Get(\"ElectricFieldReader\")\n",
    "            detector = data.Get(\"detector1\")\n",
    "            efield = detector.Get(\"field1d_z\")\n",
    "            no_bins = efield.GetNbinsX()\n",
    "            bin_size = 0.1/no_bins\n",
    "            \n",
    "            pos = p*10**(-3)\n",
    "                \n",
    "            placement = -0.05\n",
    "            for bin in range(no_bins):  \n",
    "                placement += bin_size\n",
    "                if placement >= pos:\n",
    "                    field_strength = arr.array('f', [efield.GetBinContent(bin)])\n",
    "                    field_values = np.concatenate((field_values, field_strength))\n",
    "                    break\n",
    "                    \n",
    "        each_field = np.concatenate((each_field, field_values))\n",
    "    each_field = each_field.reshape((len(files_tot), len(position), 1))\n",
    "        \n",
    "    return each_field\n",
    "\n",
    "def array_data(field_x, field_y, time_vals):\n",
    "    field_data = arr.array('f', [])\n",
    "    for x_data, y_data in zip(field_x, field_y):\n",
    "        data_tot = arr.array('f', [])\n",
    "        for x, y in zip(x_data, y_data):\n",
    "            y_array = arr.array('f', [])\n",
    "            for t in time_vals:\n",
    "                if x[-1] < t:\n",
    "                    y_array.append(0)\n",
    "                    if len(y_array) == len(time_vals):\n",
    "                        data_tot = np.concatenate((data_tot, y_array))\n",
    "                \n",
    "                else:\n",
    "                    for i in range(len(x)):\n",
    "                        if x[i] >= t and x[i-1] < t:\n",
    "                            y_array.append(y[i])\n",
    "                            if len(y_array) == len(time_vals):\n",
    "                                data_tot = np.concatenate((data_tot, y_array))\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "    \n",
    "        field_data = np.concatenate((field_data, data_tot))\n",
    "    field_data = field_data.reshape((len(field_x), len(x_data), len(time_vals)))\n",
    "\n",
    "    return field_data\n",
    "\n",
    "files1 = [\"data_10ps_n40.root\", \"extra_data_n35.root\", \"data_10ps_n30.root\", \"extra_data_n25.root\",\"data_10ps_n20.root\", \"extra_data_n15.root\", \"data_10ps_n10.root\", \"extra_data_n5.root\", \"data_10ps_0.root\"] \n",
    "files2 = [\"less_overbias_n40.root\", \"less_overbias_n35.root\", \"less_overbias_n30.root\", \"less_overbias_n25.root\", \"less_overbias_n20.root\", \"less_overbias_n15.root\", \"less_overboas_n10.root\", \"less_overbias_n5.root\", \"less_overbias_0.root\"] \n",
    "positions = [40, 35, 30, 25, 20, 15, 10, 5, 0] \n",
    "\n",
    "x_values1, y_values1, pulse_names1 = [], [], []\n",
    "for dat in files1:\n",
    "    pulse, x_dat, y_dat = collect_pulse_data(dat)\n",
    "    pulse_names1.append(pulse)\n",
    "    x_values1.append(np.array(x_dat))\n",
    "    y_values1.append(np.array(y_dat))\n",
    "\n",
    "x_values2, y_values2, pulse_names2 = [], [], []\n",
    "for dat in files2:\n",
    "    pulse, x_dat, y_dat = collect_pulse_data(dat)\n",
    "    pulse_names2.append(pulse)\n",
    "    x_values2.append(np.array(x_dat))\n",
    "    y_values2.append(np.array(y_dat))\n",
    "\n",
    "x_val = [x_values1]+[x_values2]\n",
    "y_val = [y_values1]+[y_values2]\n",
    "\n",
    "data_tot = array_data(x_val, y_val, np.linspace(0.1,10,num=100))\n",
    "print(data_tot)\n",
    "\n",
    "files = [files1]+[files2]\n",
    "e_field = collect_efield(files, positions)\n",
    "print(e_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "column_names = ['Current_pulse', 'E_field']\n",
    "\n",
    "x_train = data_tot.astype(\"float32\")\n",
    "y_train = e_field.astype(\"float32\")\n",
    "\n",
    "def build_and_compile_model():\n",
    "  model = keras.Sequential([\n",
    "    #layers.Embedding(input_dim=100, output_dim=100),\n",
    "    layers.GRU(100, return_sequences=True),\n",
    "    layers.SimpleRNN(100),\n",
    "    layers.Dense(1000, activation='relu'),\n",
    "    layers.Dense(1000, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model\n",
    "\n",
    "model = build_and_compile_model()\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    verbose=0, epochs=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  #plt.ylim(0,1000)\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  \n",
    "plot_loss(history)\n",
    "print(history.history['loss'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
